{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arofenitra/Scientific-Computing/blob/main/image_processing/image_compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqpcNKaATCzK"
      },
      "source": [
        "# Definition, methods\n",
        "- Goal : To reduce the cost of storage of a digital image.\n",
        "\n",
        "- Lossy and lossless image compression\n",
        "Lossless compression when no information is lost during the compression-decompression process, The perfect recovery of the original image is achieved. We can use in text compression and all methods that requires full recovery of the data. Otherwise it is lossy compression, we can use it for image compression or video compression where the full recovery of the data is not needed\n",
        "- Methods : Lossy compression, using Transform coding (DCT compression and Wavelet based image compression)\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/arofenitra/Scientific-Computing/blob/main/image_processing/compression_images/image_compression_method.jpeg?raw=1\">  \n",
        "\n",
        "Wavelet based compression:   \n",
        "<img src=\"https://github.com/arofenitra/Scientific-Computing/blob/main/image_processing/compression_images/block_diagram_of_the_jpeg_2000_encoder_algorithm_bdataflow.jpeg?raw=1\">  \n",
        "\n",
        "DCT based compression:  \n",
        "<img src=\"https://github.com/arofenitra/Scientific-Computing/blob/main/image_processing/compression_images/block_diagram_of_sequential_jpeg_encoder_and_decoder.jpeg?raw=1\">  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwoMGJhxeYLe"
      },
      "source": [
        "##JPEG compression algorithm\n",
        "\n",
        "### Color space inversion:\n",
        "\n",
        "Convert the image from RGB (range: $\\left[0,\\cdots,255\\right])$ to YCbCr (range: $\\left[0,\\cdots,255\\right])$  space.\n",
        "Here is the matrix of transformation:\n",
        "\n",
        "$$\\left(\\begin{matrix}Y\\\\Cb-128\\\\Cr-128\\\\\\end{matrix}\\right)=\\begin{pmatrix}0.299&0.587&0.114\\\\-0.1687&-0.3313&0.5\\\\0.5&-0.4187&-0.0813\\\\\\end{pmatrix}\\left(\\begin{matrix}R\\\\G\\\\B\\\\\\end{matrix}\\right)$$\n",
        "\n",
        "### Down sampling:\n",
        "\n",
        "Reduce the resolution of the Cb and Cr components by a factor of 2 in both horizontal and vertical directions.\n",
        "\n",
        "### Division into 8*8-pixel block:\n",
        "\n",
        "Split the image into 8x8 pixel blocks.\n",
        "\n",
        "### The integral transform\n",
        "\n",
        "It uses DCT transform . Application of the DCT to each 8*8 block:\n",
        "\n",
        "$$ X_{u,v}=\\frac{1}{4}\\alpha\\left(u\\right)\\alpha\\left(v\\right)\\sum_{x=0}^{7}{\\sum_{y=0}^{7}f\\left(x,y\\right)\\cos{\\left(\\frac{\\left(2x+1\\right)u\\pi}{16}\\right)}}\\cos{\\left(\\frac{\\left(2y+1\\right)v\\pi}{16}\\right)} $$\n",
        "\n",
        "Where $\\alpha\\left(w\\right)=\\frac{1}{\\sqrt2}\\mathrm{if\\ }w=0\\mathrm{\\ and\\ 0\\ otherwise}$\n",
        "\n",
        "### Quantization\n",
        "\n",
        "Divide each DCT coefficient by a corresponding value in a quantization matrix, then round to the nearest integer: $X_{i,j}=\\mathrm{round}\\left(X_{i,j}/Q_{i,j}\\right)$, where the matrix of quantization is Q.\n",
        "\n",
        "$$Q=\\left(\\begin{matrix}16&11&10&16&24&40&51&61\\\\12&12&14&19&26&58&60&55\\\\14&13&16&24&40&57&69&56\\\\14&17&22&29&51&87&80&62\\\\18&22&37&56&68&109&103&77\\\\24&35&55&64&81&104&113&92\\\\49&64&78&87&103&121&120&101\\\\72&92&95&98&112&100&103&99\\\\\\end{matrix}\\right)$$\n",
        "\n",
        "### Entropy Encoding\n",
        "\n",
        "**Run Length Encoding(RLE)**: Data compression where the sequences of the same data value are stored as single data value and count (the number of consecutive of the same value.\n",
        "\n",
        "**LZ77 compression + Huffman Coding** (zlib.compress): Identifies repeated sequences of bytes and replaces them with references to earlier occurrences, and encoding frequently occurring bytes with shorter codes.\n",
        "\n",
        "### Entropy decoding:\n",
        "\n",
        "Perform the inverse of the encoding steps (zlib.decompress), and do the inverse of the RLE.\n",
        "\n",
        "### Dequantization:\n",
        "\n",
        "Multiply the quantized coefficients by the quantization matrix to get the dequantized coefficients: X_{i,j}=X_{i,j}\\cdot Q_{i,j}\n",
        "\n",
        "### Inverse integral transform:\n",
        "\n",
        "The inverse DCT is :\n",
        "\n",
        "$$f\\left(x,y\\right)=\\frac{1}{4}\\sum_{u=0}^{7}{\\sum_{v=0}^{7}{\\alpha\\left(u\\right)\\alpha\\left(v\\right)X_{u,v}}\\cos{\\left(\\frac{\\left(2x+1\\right)u\\pi}{16}\\right)}}\\cos{\\left(\\frac{\\left(2y+1\\right)v\\pi}{16}\\right)}$$\n",
        "\n",
        "### Assembling block and resampling and Color reconversion\n",
        "\n",
        "Assemble the 8x8 blocks back into a full image. And convert the YcbCr color to RGB\n",
        "\n",
        "$$\\left(\\begin{matrix}R\\\\G\\\\B\\\\\\end{matrix}\\right)=\\begin{pmatrix}1&0&1.402\\\\1&-0.344136&-0.714136\\\\1&1.772&0\\\\\\end{pmatrix}\\left(\\begin{matrix}Y\\\\Cb-128\\\\Cr-128\\\\\\end{matrix}\\right)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JPEG 2000 compression algorithm\n",
        "\n",
        "### Color space inversion:\n",
        "Convert the image from RGB to YCbCr space (the same as in DCT)\n",
        "\n",
        "### The integral transform is wavelet transform.\n",
        "\n",
        "The wavelet transforms (Discrete wavelet transform) $N$ real numbers $x_0,\\ldots,x_{N-1}$ into two sequences of $N/2$ real numbers: the approximation coefficients $a_0,\\ldots,a_{N/2-1}$ and the detail coefficients $d_0,\\ldots,d_{N/2-1}$. For Haar wavelet, the 2 filters are low pass filter: $h=\\left[1,1\\right]/\\sqrt{2}$ and the high pass filter $g=\\left[1,-1\\right]/\\sqrt{2}$ so\n",
        "a_k=\\sum_{n=0}^{1}{h_nx_{2k+n}}=\\left(x_{2k}+x_{2k+1}\\right)/\\sqrt2;d_k=\\sum_{n=0}^{1}{g_nx_{2k+n}}=x_{2k}-x_{2k+1})/\\sqrt2\n",
        "For the case of m-th level of transformation, the 2 coefficients are:\n",
        "a_k^m=\\left(a_{2k}^{m-1}+a_{2k+1}^{m-1}\\right)/\\sqrt2;d_k^m=\\left(a_{2k}^{m-1}-a_{2k+1}^{m-1}\\right)/\\sqrt2\n",
        "\n",
        "\tQuantization: involves scaling the wavelet coefficients by a factor, which is typically a power of 2, and then rounding them to the nearest integer: \\hat{c}=\\left\\lfloor\\ \\frac{c}{\\Delta}\\ \\right\\rfloor , where \\Delta is the quantization step size.\n",
        "\n",
        "\tEntropy Encoding\n",
        "Run Length Encoding (RLE): Data compression where the sequences of the same data value are stored as single data value and count (the number of consecutive of the same value.\n",
        "LZ77 compression + Huffman Coding (zlib.compress): Identifies repeated sequences of bytes and replaces them with references to earlier occurrences, and encoding frequently occurring bytes with shorter codes.\n",
        "\n",
        "\tEntropy decoding: Perform the inverse of the encoding steps (zlib.decompress), and do the inverse of the RLE.\n",
        "\n",
        "\tDequantization: Multiply the quantized coefficients by the quantization step size to get the dequantized coefficients: c=\\hat{c}\\ \\Delta\n",
        "\n",
        "\tInverse integral transform\n",
        "The inverse wavelet is :\n",
        "x_{2k}=\\frac{a_k+d_k}{\\sqrt2},\\emsp x_{2k+1}=\\frac{a_k-d_k}{\\sqrt2}\n",
        "\tColor reconversion\n",
        "Convert the YcbCr color to RGB (the same as in DCT)\n"
      ],
      "metadata": {
        "id": "jtj98T-2N1Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DCT-based : JPEG Compression with downsampling methods"
      ],
      "metadata": {
        "id": "HFkZ4d9LIKcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from itertools import groupby\n",
        "import zlib\n",
        "\n",
        "def jpeg_compression(image_path, quality=50):\n",
        "    # Reading of the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Conversion of the image into YCbCr color space\n",
        "    img_ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Downsample the Cb and Cr components\n",
        "    img_ycbcr_downsampled = img_ycbcr.copy()\n",
        "    img_ycbcr_downsampled_Cb = cv2.resize(img_ycbcr[:, :, 1], (img_ycbcr.shape[1] // 2, img_ycbcr.shape[0] // 2), interpolation=cv2.INTER_AREA)\n",
        "    img_ycbcr_downsampled_Cr = cv2.resize(img_ycbcr[:, :, 2], (img_ycbcr.shape[1] // 2, img_ycbcr.shape[0] // 2), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Split the image into 8x8 blocks\n",
        "    blocks_Y = [img_ycbcr_downsampled[i:i+8, j:j+8, 0] for i in range(0, img_ycbcr_downsampled.shape[0], 8) for j in range(0, img_ycbcr_downsampled.shape[1], 8)]\n",
        "    blocks_Cb = [img_ycbcr_downsampled_Cb[i:i+8, j:j+8] for i in range(0, img_ycbcr_downsampled.shape[0] // 2, 8) for j in range(0, img_ycbcr_downsampled.shape[1] // 2, 8)]\n",
        "    blocks_Cr = [img_ycbcr_downsampled_Cr[i:i+8, j:j+8] for i in range(0, img_ycbcr_downsampled.shape[0] // 2, 8) for j in range(0, img_ycbcr_downsampled.shape[1] // 2, 8)]\n",
        "\n",
        "    quantization_matrix = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    compressed_blocks_Y = []\n",
        "    compressed_blocks_Cb = []\n",
        "    compressed_blocks_Cr = []\n",
        "\n",
        "    for block in blocks_Y:\n",
        "        block_float = np.float32(block)\n",
        "        dct_block_Y = cv2.dct(block_float)\n",
        "        quantized_block_Y = np.round(dct_block_Y / (quantization_matrix * (quality / 100.0)))\n",
        "        compressed_blocks_Y.append(quantized_block_Y)\n",
        "\n",
        "    for block in blocks_Cb:\n",
        "        block_float = np.float32(block)\n",
        "        dct_block_Cb = cv2.dct(block_float)\n",
        "        quantized_block_Cb = np.round(dct_block_Cb / (quantization_matrix * (quality / 100.0)))\n",
        "        compressed_blocks_Cb.append(quantized_block_Cb)\n",
        "\n",
        "    for block in blocks_Cr:\n",
        "        block_float = np.float32(block)\n",
        "        dct_block_Cr = cv2.dct(block_float)\n",
        "        quantized_block_Cr = np.round(dct_block_Cr / (quantization_matrix * (quality / 100.0)))\n",
        "        compressed_blocks_Cr.append(quantized_block_Cr)\n",
        "\n",
        "    # RLE algorithm and zlib compression\n",
        "    def rle_and_compress(blocks):\n",
        "        bitstream = np.array(blocks).astype(int).flatten()\n",
        "        bitstream = ' '.join(f'{k} {len(list(g))}' for k, g in groupby(bitstream))\n",
        "        return zlib.compress(bitstream.encode())\n",
        "\n",
        "    compressed_blocks_Y = rle_and_compress(compressed_blocks_Y)\n",
        "    compressed_blocks_Cb = rle_and_compress(compressed_blocks_Cb) if compressed_blocks_Cb else None\n",
        "    compressed_blocks_Cr = rle_and_compress(compressed_blocks_Cr) if compressed_blocks_Cr else None\n",
        "\n",
        "    return compressed_blocks_Y, compressed_blocks_Cb, compressed_blocks_Cr, img_ycbcr.shape\n",
        "\n",
        "# Decoding process\n",
        "def jpeg_decompression(compressed_blocks_Y, compressed_blocks_Cb, compressed_blocks_Cr, shape, quality=50):\n",
        "\n",
        "    def decompress_and_rle(compressed_blocks):\n",
        "        if compressed_blocks is None:\n",
        "            return None\n",
        "        bitstream = zlib.decompress(compressed_blocks).decode().split()\n",
        "        result_split = []\n",
        "        for i in range(0, len(bitstream), 2):\n",
        "            result_split.extend([int(bitstream[i])] * int(bitstream[i + 1]))\n",
        "        return np.array(result_split).reshape(-1, 8, 8)\n",
        "\n",
        "    compressed_blocks_Y = decompress_and_rle(compressed_blocks_Y)\n",
        "    compressed_blocks_Cb = decompress_and_rle(compressed_blocks_Cb)\n",
        "    compressed_blocks_Cr = decompress_and_rle(compressed_blocks_Cr)\n",
        "\n",
        "    img_reconstructed_Y = np.zeros((shape[0], shape[1]), dtype=np.uint8)\n",
        "    img_reconstructed_Cb = np.zeros((shape[0] // 2, shape[1] // 2), dtype=np.uint8) if compressed_blocks_Cb is not None else None\n",
        "    img_reconstructed_Cr = np.zeros((shape[0] // 2, shape[1] // 2), dtype=np.uint8) if compressed_blocks_Cr is not None else None\n",
        "\n",
        "    quantization_matrix = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    def dequantize_and_idct(blocks, img_reconstructed):\n",
        "        for idx, block in enumerate(blocks):\n",
        "            dequantized_block = block * (quantization_matrix * (quality / 100.0))\n",
        "            idct_block = cv2.idct(dequantized_block)\n",
        "            i, j = divmod(idx, img_reconstructed.shape[1] // 8)\n",
        "            img_reconstructed[i*8:(i+1)*8, j*8:(j+1)*8] = idct_block\n",
        "\n",
        "    dequantize_and_idct(compressed_blocks_Y, img_reconstructed_Y)\n",
        "    if compressed_blocks_Cb is not None:\n",
        "        dequantize_and_idct(compressed_blocks_Cb, img_reconstructed_Cb)\n",
        "    if compressed_blocks_Cr is not None:\n",
        "        dequantize_and_idct(compressed_blocks_Cr, img_reconstructed_Cr)\n",
        "\n",
        "    # Upsample the Cb and Cr components to recover their original size\n",
        "    if img_reconstructed_Cb is not None and img_reconstructed_Cr is not None:\n",
        "        img_reconstructed_Cb_upsampled = cv2.resize(img_reconstructed_Cb, (shape[1], shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "        img_reconstructed_Cr_upsampled = cv2.resize(img_reconstructed_Cr, (shape[1], shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "        img_reconstructed = cv2.merge([img_reconstructed_Y, img_reconstructed_Cb_upsampled, img_reconstructed_Cr_upsampled])\n",
        "    else:\n",
        "        img_reconstructed = img_reconstructed_Y\n",
        "\n",
        "    # Convert the reconstructed image back to BGR color space\n",
        "    img_rgb = cv2.cvtColor(img_reconstructed, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "    return img_rgb\n"
      ],
      "metadata": {
        "id": "2E_epZHJINa-"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "kodim01_path = 'kodim01.png'\n",
        "kodim01_code = jpeg_compression(kodim01_path, quality=200)\n",
        "kodim01_decode = jpeg_decompression(kodim01_code[0],kodim01_code[1],kodim01_code[2],kodim01_code[3], quality=200)\n",
        "filename = \"kodim01_decode_dct2.png\"\n",
        "cv2.imwrite(filename, kodim01_decode)\n",
        "print(os.path.getsize(kodim01_path))\n",
        "print(os.path.getsize(filename))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6ScrU8NLiM8",
        "outputId": "07fce271-3b65-4d62-8899-d17c09e772db"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "736501\n",
            "737595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jpeg Compression without downsampling\n"
      ],
      "metadata": {
        "id": "doUvuHwMrr_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from itertools import groupby\n",
        "import zlib\n",
        "\n",
        "def jpeg_compression(image_path, quality=50):\n",
        "    # Reading of the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Conversion of the image into YCbCr color space\n",
        "    img_ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Split the image into 8x8 blocks\n",
        "    blocks = [img_ycbcr[i:i+8, j:j+8] for i in range(0, img_ycbcr.shape[0], 8) for j in range(0, img_ycbcr.shape[1], 8)]\n",
        "\n",
        "    quantization_matrix = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    compressed_blocks_Y = []\n",
        "    compressed_blocks_Cb = []\n",
        "    compressed_blocks_Cr = []\n",
        "\n",
        "    for block in blocks:\n",
        "        block_float = np.float32(block)\n",
        "        dct_block_Y = cv2.dct(block_float[:, :, 0])\n",
        "        quantized_block_Y = np.round(dct_block_Y / (quantization_matrix * (quality / 100.0)))\n",
        "        compressed_blocks_Y.append(quantized_block_Y)\n",
        "\n",
        "        if img_ycbcr.shape[2] == 3:\n",
        "            dct_block_Cb = cv2.dct(block_float[:, :, 1])\n",
        "            dct_block_Cr = cv2.dct(block_float[:, :, 2])\n",
        "            quantized_block_Cb = np.round(dct_block_Cb / (quantization_matrix * (quality / 100.0)))\n",
        "            quantized_block_Cr = np.round(dct_block_Cr / (quantization_matrix * (quality / 100.0)))\n",
        "            compressed_blocks_Cb.append(quantized_block_Cb)\n",
        "            compressed_blocks_Cr.append(quantized_block_Cr)\n",
        "\n",
        "    # RLE algorithm and zlib compression\n",
        "    def rle_and_compress(blocks):\n",
        "        bitstream = np.array(blocks).astype(int).flatten()\n",
        "        bitstream = ' '.join(f'{k} {len(list(g))}' for k, g in groupby(bitstream))\n",
        "        return zlib.compress(bitstream.encode())\n",
        "\n",
        "    compressed_blocks_Y = rle_and_compress(compressed_blocks_Y)\n",
        "    compressed_blocks_Cb = rle_and_compress(compressed_blocks_Cb) if compressed_blocks_Cb else None\n",
        "    compressed_blocks_Cr = rle_and_compress(compressed_blocks_Cr) if compressed_blocks_Cr else None\n",
        "\n",
        "    return compressed_blocks_Y, compressed_blocks_Cb, compressed_blocks_Cr, img_ycbcr.shape\n",
        "\n",
        "# Decoding process\n",
        "def jpeg_decompression(compressed_blocks_Y, compressed_blocks_Cb, compressed_blocks_Cr, shape, quality=50):\n",
        "\n",
        "    def decompress_and_rle(compressed_blocks):\n",
        "        if compressed_blocks is None:\n",
        "            return None\n",
        "        bitstream = zlib.decompress(compressed_blocks).decode().split()\n",
        "        result_split = []\n",
        "        for i in range(0, len(bitstream), 2):\n",
        "            result_split.extend([int(bitstream[i])] * int(bitstream[i + 1]))\n",
        "        return np.array(result_split).reshape(-1, 8, 8)\n",
        "\n",
        "    compressed_blocks_Y = decompress_and_rle(compressed_blocks_Y)\n",
        "    compressed_blocks_Cb = decompress_and_rle(compressed_blocks_Cb)\n",
        "    compressed_blocks_Cr = decompress_and_rle(compressed_blocks_Cr)\n",
        "\n",
        "    img_reconstructed_Y = np.zeros((shape[0], shape[1]), dtype=np.uint8)\n",
        "    img_reconstructed_Cb = np.zeros((shape[0], shape[1]), dtype=np.uint8) if compressed_blocks_Cb is not None else None\n",
        "    img_reconstructed_Cr = np.zeros((shape[0], shape[1]), dtype=np.uint8) if compressed_blocks_Cr is not None else None\n",
        "\n",
        "    quantization_matrix = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    def dequantize_and_idct(blocks, img_reconstructed):\n",
        "        for idx, block in enumerate(blocks):\n",
        "            dequantized_block = block * (quantization_matrix * (quality / 100.0))\n",
        "            idct_block = cv2.idct(dequantized_block)\n",
        "            i, j = divmod(idx, shape[1] // 8)\n",
        "            img_reconstructed[i*8:(i+1)*8, j*8:(j+1)*8] = idct_block\n",
        "\n",
        "    dequantize_and_idct(compressed_blocks_Y, img_reconstructed_Y)\n",
        "    if compressed_blocks_Cb is not None:\n",
        "        dequantize_and_idct(compressed_blocks_Cb, img_reconstructed_Cb)\n",
        "    if compressed_blocks_Cr is not None:\n",
        "        dequantize_and_idct(compressed_blocks_Cr, img_reconstructed_Cr)\n",
        "\n",
        "    if img_reconstructed_Cb is not None and img_reconstructed_Cr is not None:\n",
        "        img_reconstructed = cv2.merge([img_reconstructed_Y, img_reconstructed_Cb, img_reconstructed_Cr])\n",
        "    else:\n",
        "        img_reconstructed = img_reconstructed_Y\n",
        "\n",
        "    # Convert the reconstructed image back to BGR color space\n",
        "    img_rgb = cv2.cvtColor(img_reconstructed, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "    return img_rgb\n",
        "\n"
      ],
      "metadata": {
        "id": "4P_d2DRorvXd"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "kodim01_path = 'kodim01.png'\n",
        "kodim01_code = jpeg_compression(kodim01_path, quality=500)\n",
        "kodim01_decode = jpeg_decompression(kodim01_code[0],kodim01_code[1],kodim01_code[2],kodim01_code[3], quality=500)\n",
        "filename = \"kodim01_decode_dct.png\"\n",
        "cv2.imwrite(filename, kodim01_decode)\n",
        "print(os.path.getsize(kodim01_path))\n",
        "print(os.path.getsize(filename))\n"
      ],
      "metadata": {
        "id": "oZPjZKjY_I4a",
        "outputId": "9503cbaf-33c7-4f00-85b2-8a35b072031b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "736501\n",
            "575425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallel version of JPEG compression"
      ],
      "metadata": {
        "id": "3CneTi8EDcAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py"
      ],
      "metadata": {
        "id": "nK7O-XUVDfhd",
        "outputId": "c4d758ec-9bf7-45df-82d6-2ded7020a772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.1.tar.gz (466 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/466.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m460.8/466.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.1-cp310-cp310-linux_x86_64.whl size=4266343 sha256=5dfc9c27f9e9ab5d27fdf082bcd38a05e190542ff5618564070d65dfc244fc55\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/ca/13/13218a83854023ccec184e3af482f0f038b434aa32c19afee8\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parallel_jpeg.py\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from itertools import groupby\n",
        "import zlib\n",
        "from mpi4py import MPI\n",
        "import os\n",
        "def parallel_jpeg_compression(image_path, quality=50):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Master process reads the image and splits it into chunks\n",
        "        img = cv2.imread(image_path)\n",
        "        img_ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "        rows_per_processor = img_ycbcr.shape[0] // size\n",
        "\n",
        "        for i in range(1, size):\n",
        "            start_row = i * rows_per_processor\n",
        "            end_row = (i + 1) * rows_per_processor if i != size - 1 else img_ycbcr.shape[0]\n",
        "            chunk = img_ycbcr[start_row:end_row, :, :]\n",
        "            comm.send(chunk, dest=i, tag=i)\n",
        "\n",
        "        # Master process handles the first chunk\n",
        "        chunk = img_ycbcr[:rows_per_processor, :, :]\n",
        "        compressed_chunk = jpeg_compress_chunk(chunk, quality)\n",
        "        compressed_data = [compressed_chunk]\n",
        "\n",
        "        for i in range(1, size):\n",
        "            compressed_chunk = comm.recv(source=i, tag=i)\n",
        "            compressed_data.append(compressed_chunk)\n",
        "\n",
        "        return compressed_data, img_ycbcr.shape\n",
        "    else:\n",
        "        # Worker processes receive their chunk and compress it\n",
        "        chunk = comm.recv(source=0, tag=rank)\n",
        "        compressed_chunk = jpeg_compress_chunk(chunk, quality)\n",
        "        comm.send(compressed_chunk, dest=0, tag=rank)\n",
        "\n",
        "def jpeg_compress_chunk(chunk, quality):\n",
        "    blocks = [chunk[i:i+8, j:j+8] for i in range(0, chunk.shape[0], 8) for j in range(0, chunk.shape[1], 8)]\n",
        "\n",
        "    quantization_matrix = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    compressed_blocks_Y = []\n",
        "    compressed_blocks_Cb = []\n",
        "    compressed_blocks_Cr = []\n",
        "\n",
        "    for block in blocks:\n",
        "        block_float = np.float32(block)\n",
        "        dct_block_Y = cv2.dct(block_float[:, :, 0])\n",
        "        quantized_block_Y = np.round(dct_block_Y / (quantization_matrix * (quality / 100.0)))\n",
        "        compressed_blocks_Y.append(quantized_block_Y)\n",
        "\n",
        "        if chunk.shape[2] == 3:\n",
        "            dct_block_Cb = cv2.dct(block_float[:, :, 1])\n",
        "            dct_block_Cr = cv2.dct(block_float[:, :, 2])\n",
        "            quantized_block_Cb = np.round(dct_block_Cb / (quantization_matrix * (quality / 100.0)))\n",
        "            quantized_block_Cr = np.round(dct_block_Cr / (quantization_matrix * (quality / 100.0)))\n",
        "            compressed_blocks_Cb.append(quantized_block_Cb)\n",
        "            compressed_blocks_Cr.append(quantized_block_Cr)\n",
        "\n",
        "    def rle_and_compress(blocks):\n",
        "        bitstream = np.array(blocks).astype(int).flatten()\n",
        "        bitstream = ' '.join(f'{k} {len(list(g))}' for k, g in groupby(bitstream))\n",
        "        return zlib.compress(bitstream.encode())\n",
        "\n",
        "    compressed_blocks_Y = rle_and_compress(compressed_blocks_Y)\n",
        "    compressed_blocks_Cb = rle_and_compress(compressed_blocks_Cb) if compressed_blocks_Cb else None\n",
        "    compressed_blocks_Cr = rle_and_compress(compressed_blocks_Cr) if compressed_blocks_Cr else None\n",
        "\n",
        "    return compressed_blocks_Y, compressed_blocks_Cb, compressed_blocks_Cr, chunk.shape\n",
        "\n",
        "# Decoding process\n",
        "def parallel_jpeg_decompression(compressed_data, shape, quality=50):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        rows_per_processor = shape[0] // size\n",
        "        chunks = []\n",
        "        for i in range(size):\n",
        "            start_row = i * rows_per_processor\n",
        "            end_row = (i + 1) * rows_per_processor if i != size - 1 else shape[0]\n",
        "            compressed_chunk = (compressed_data[i][0], compressed_data[i][1], compressed_data[i][2], (end_row - start_row, shape[1], 3))\n",
        "            chunks.append(compressed_chunk)\n",
        "\n",
        "        for i in range(1, size):\n",
        "            comm.send(chunks[i], dest=i, tag=i)\n",
        "\n",
        "        img_reconstructed = jpeg_decompress_chunk(chunks[0], quality)\n",
        "        reconstructed_chunks = [img_reconstructed]\n",
        "\n",
        "        for i in range(1, size):\n",
        "            img_reconstructed = comm.recv(source=i, tag=i)\n",
        "            reconstructed_chunks.append(img_reconstructed)\n",
        "\n",
        "        img_reconstructed = np.vstack(reconstructed_chunks)\n",
        "        img_rgb = cv2.cvtColor(img_reconstructed, cv2.COLOR_YCrCb2BGR)\n",
        "        return img_rgb\n",
        "    else:\n",
        "        chunk = comm.recv(source=0, tag=rank)\n",
        "        img_reconstructed = jpeg_decompress_chunk(chunk, quality)\n",
        "        comm.send(img_reconstructed, dest=0, tag=rank)\n",
        "\n",
        "def jpeg_decompress_chunk(compressed_chunk, quality):\n",
        "    compressed_blocks_Y, compressed_blocks_Cb, compressed_blocks_Cr, chunk_shape = compressed_chunk\n",
        "\n",
        "    def decompress_and_rle(compressed_blocks):\n",
        "        if compressed_blocks is None:\n",
        "            return None\n",
        "        bitstream = zlib.decompress(compressed_blocks).decode().split()\n",
        "        result_split = []\n",
        "        for i in range(0, len(bitstream), 2):\n",
        "            result_split.extend([int(bitstream[i])] * int(bitstream[i + 1]))\n",
        "        return np.array(result_split).reshape(-1, 8, 8)\n",
        "\n",
        "    compressed_blocks_Y = decompress_and_rle(compressed_blocks_Y)\n",
        "    compressed_blocks_Cb = decompress_and_rle(compressed_blocks_Cb)\n",
        "    compressed_blocks_Cr = decompress_and_rle(compressed_blocks_Cr)\n",
        "\n",
        "    img_reconstructed_Y = np.zeros((chunk_shape[0], chunk_shape[1]), dtype=np.uint8)\n",
        "    img_reconstructed_Cb = np.zeros((chunk_shape[0], chunk_shape[1]), dtype=np.uint8) if compressed_blocks_Cb is not None else None\n",
        "    img_reconstructed_Cr = np.zeros((chunk_shape[0], chunk_shape[1]), dtype=np.uint8) if compressed_blocks_Cr is not None else None\n",
        "\n",
        "    quantization_matrix = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    def dequantize_and_idct(blocks, img_reconstructed):\n",
        "        for idx, block in enumerate(blocks):\n",
        "            dequantized_block = block * (quantization_matrix * (quality / 100.0))\n",
        "            idct_block = cv2.idct(dequantized_block)\n",
        "            i, j = divmod(idx, chunk_shape[1] // 8)\n",
        "            img_reconstructed[i*8:(i+1)*8, j*8:(j+1)*8] = idct_block\n",
        "\n",
        "    dequantize_and_idct(compressed_blocks_Y, img_reconstructed_Y)\n",
        "    if compressed_blocks_Cb is not None:\n",
        "        dequantize_and_idct(compressed_blocks_Cb, img_reconstructed_Cb)\n",
        "    if compressed_blocks_Cr is not None:\n",
        "        dequantize_and_idct(compressed_blocks_Cr, img_reconstructed_Cr)\n",
        "\n",
        "    if img_reconstructed_Cb is not None and img_reconstructed_Cr is not None:\n",
        "        img_reconstructed = cv2.merge([img_reconstructed_Y, img_reconstructed_Cb, img_reconstructed_Cr])\n",
        "    else:\n",
        "        img_reconstructed = img_reconstructed_Y\n",
        "\n",
        "    return img_reconstructed\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    kodim01_path = 'kodim01.png'\n",
        "    compressed_data, shape = parallel_jpeg_compression(kodim01_path, quality=500)\n",
        "    kodim01_decode = parallel_jpeg_decompression(compressed_data, shape, quality=500)\n",
        "    filename = \"kodim01_decode_dct_parallel.png\"\n",
        "    if MPI.COMM_WORLD.Get_rank() == 0:\n",
        "        cv2.imwrite(filename, kodim01_decode)\n",
        "        print(os.path.getsize(kodim01_path))\n",
        "        print(os.path.getsize(filename))\n"
      ],
      "metadata": {
        "id": "6tYTj6nHDoX3",
        "outputId": "ed9a62ae-6310-479a-f7f5-ed43c0e9f354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting parallel_jpeg.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpiexec --allow-run-as-root python parallel_jpeg.py"
      ],
      "metadata": {
        "id": "YOo5ZEgWDvY_",
        "outputId": "6cd0ad81-3337-4aa0-d605-63a4bd5ad640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "736501\n",
            "575425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wavelet based : JPEG2000 Compression algorithm"
      ],
      "metadata": {
        "id": "E3LpRQtHy-In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywavelets"
      ],
      "metadata": {
        "id": "3hrBrA3h1tss",
        "outputId": "35250eed-5156-431e-875a-002fd9e5e852",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pywavelets\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from pywavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pywavelets\n",
            "Successfully installed pywavelets-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pywt\n",
        "import zlib\n",
        "from itertools import groupby\n",
        "import os\n",
        "\n",
        "def quantize_coefficients(coeffs, threshold):\n",
        "    return np.where(np.abs(coeffs) < threshold, 0, coeffs).astype(int)\n",
        "\n",
        "def jpeg_2000(image_path, threshold=10):\n",
        "    # Reading of the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Conversion of the image into YCbCr color space\n",
        "    img_ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Split the image into components\n",
        "    Y, Cb, Cr = cv2.split(img_ycbcr)\n",
        "\n",
        "    # Wavelet transform\n",
        "    coeffs_Y = pywt.wavedec2(Y, 'db1', level=2)\n",
        "    coeffs_Cb = pywt.wavedec2(Cb, 'db1', level=2)\n",
        "    coeffs_Cr = pywt.wavedec2(Cr, 'db1', level=2)\n",
        "\n",
        "    # Quantization\n",
        "    def quantize(coeffs, threshold):\n",
        "        quantized_coeffs = []\n",
        "        for coeff in coeffs:\n",
        "            if isinstance(coeff, tuple):\n",
        "                quantized_coeffs.append(tuple(quantize_coefficients(c, threshold) for c in coeff))\n",
        "            else:\n",
        "                quantized_coeffs.append(quantize_coefficients(coeff, threshold))\n",
        "        return quantized_coeffs\n",
        "\n",
        "    quantized_coeffs_Y = quantize(coeffs_Y, threshold)\n",
        "    quantized_coeffs_Cb = quantize(coeffs_Cb, threshold)\n",
        "    quantized_coeffs_Cr = quantize(coeffs_Cr, threshold)\n",
        "\n",
        "    # Flatten the quantized coefficients for RLE and compression\n",
        "    def flatten_coeffs(coeffs):\n",
        "        flattened = []\n",
        "        for coeff in coeffs:\n",
        "            if isinstance(coeff, tuple):\n",
        "                for c in coeff:\n",
        "                    flattened.extend(c.flatten())\n",
        "            else:\n",
        "                flattened.extend(coeff.flatten())\n",
        "        return np.array(flattened)\n",
        "\n",
        "    flattened_coeffs_Y = flatten_coeffs(quantized_coeffs_Y)\n",
        "    flattened_coeffs_Cb = flatten_coeffs(quantized_coeffs_Cb)\n",
        "    flattened_coeffs_Cr = flatten_coeffs(quantized_coeffs_Cr)\n",
        "\n",
        "    # RLE algorithm and zlib compression\n",
        "    def rle_and_compress(coeffs):\n",
        "        bitstream = ' '.join(f'{k} {len(list(g))}' for k, g in groupby(coeffs))\n",
        "        return zlib.compress(bitstream.encode())\n",
        "\n",
        "    compressed_coeffs_Y = rle_and_compress(flattened_coeffs_Y)\n",
        "    compressed_coeffs_Cb = rle_and_compress(flattened_coeffs_Cb)\n",
        "    compressed_coeffs_Cr = rle_and_compress(flattened_coeffs_Cr)\n",
        "\n",
        "    return compressed_coeffs_Y, compressed_coeffs_Cb, compressed_coeffs_Cr, img_ycbcr.shape, coeffs_Y, coeffs_Cb, coeffs_Cr\n",
        "\n",
        "# Decoding process\n",
        "def jpeg_2000_decompression(compressed_coeffs_Y, compressed_coeffs_Cb, compressed_coeffs_Cr, shape, coeffs_Y, coeffs_Cb, coeffs_Cr, threshold=10):\n",
        "\n",
        "    def decompress_and_rle(compressed_coeffs):\n",
        "        bitstream = zlib.decompress(compressed_coeffs).decode().split()\n",
        "        result_split = []\n",
        "        for i in range(0, len(bitstream), 2):\n",
        "            result_split.extend([int(float(bitstream[i]))] * int(bitstream[i + 1]))\n",
        "        return np.array(result_split)\n",
        "\n",
        "    def unflatten_coeffs(flattened_coeffs, original_coeffs):\n",
        "        unflattened = []\n",
        "        index = 0\n",
        "        for coeff in original_coeffs:\n",
        "            if isinstance(coeff, tuple):\n",
        "                unflattened.append(tuple(flattened_coeffs[index:index+c.size].reshape(c.shape) for c in coeff))\n",
        "                index += sum(c.size for c in coeff)\n",
        "            else:\n",
        "                unflattened.append(flattened_coeffs[index:index+coeff.size].reshape(coeff.shape))\n",
        "                index += coeff.size\n",
        "        return unflattened\n",
        "\n",
        "    flattened_coeffs_Y = decompress_and_rle(compressed_coeffs_Y)\n",
        "    flattened_coeffs_Cb = decompress_and_rle(compressed_coeffs_Cb)\n",
        "    flattened_coeffs_Cr = decompress_and_rle(compressed_coeffs_Cr)\n",
        "\n",
        "    # Unflatten the coefficients\n",
        "    dequantized_coeffs_Y = unflatten_coeffs(flattened_coeffs_Y, coeffs_Y)\n",
        "    dequantized_coeffs_Cb = unflatten_coeffs(flattened_coeffs_Cb, coeffs_Cb)\n",
        "    dequantized_coeffs_Cr = unflatten_coeffs(flattened_coeffs_Cr, coeffs_Cr)\n",
        "\n",
        "    # Inverse wavelet transform\n",
        "    Y_reconstructed = pywt.waverec2(dequantized_coeffs_Y, 'db1')\n",
        "    Cb_reconstructed = pywt.waverec2(dequantized_coeffs_Cb, 'db1')\n",
        "    Cr_reconstructed = pywt.waverec2(dequantized_coeffs_Cr, 'db1')\n",
        "\n",
        "    # Convert the reconstructed components to 8-bit unsigned integer format\n",
        "    Y_reconstructed = np.clip(Y_reconstructed, 0, 255).astype(np.uint8)\n",
        "    Cb_reconstructed = np.clip(Cb_reconstructed, 0, 255).astype(np.uint8)\n",
        "    Cr_reconstructed = np.clip(Cr_reconstructed, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Merge the components back into a single image\n",
        "    img_reconstructed = cv2.merge([Y_reconstructed, Cb_reconstructed, Cr_reconstructed])\n",
        "\n",
        "    # Convert the reconstructed image back to BGR color space\n",
        "    img_rgb = cv2.cvtColor(img_reconstructed, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "    return img_rgb\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2GPHv2y2rzb-"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "kodim01_path = 'kodim02.png'\n",
        "kodim01_code = jpeg_2000(kodim01_path, threshold=30)  # Adjust threshold for better results\n",
        "kodim01_decode = jpeg_2000_decompression(kodim01_code[0], kodim01_code[1], kodim01_code[2], kodim01_code[3], kodim01_code[4], kodim01_code[5], kodim01_code[6], threshold=30)\n",
        "filename = \"kodim02_decode_wavelet.png\"\n",
        "cv2.imwrite(filename, kodim01_decode)\n",
        "print(os.path.getsize(kodim01_path))\n",
        "print(os.path.getsize(filename))"
      ],
      "metadata": {
        "id": "wlUe7Y7X_S0D",
        "outputId": "5830188a-7baf-4744-9db8-5dfab01c5240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "617995\n",
            "298575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallel Version of JPEG 2000 Compression Algorithm"
      ],
      "metadata": {
        "id": "I5iMzkKUGTg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parallel_jpeg_2000.py\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pywt\n",
        "import zlib\n",
        "from itertools import groupby\n",
        "from mpi4py import MPI\n",
        "import os\n",
        "\n",
        "def quantize_coefficients(coeffs, threshold):\n",
        "    return np.where(np.abs(coeffs) < threshold, 0, coeffs).astype(int)\n",
        "\n",
        "def parallel_jpeg_2000(image_path, threshold=10):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Master process reads the image and splits it into chunks\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Unable to open/read image file: {image_path}\")\n",
        "\n",
        "        img_ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "        rows_per_processor = img_ycbcr.shape[0] // size\n",
        "\n",
        "        for i in range(1, size):\n",
        "            start_row = i * rows_per_processor\n",
        "            end_row = (i + 1) * rows_per_processor if i != size - 1 else img_ycbcr.shape[0]\n",
        "            chunk = img_ycbcr[start_row:end_row, :, :]\n",
        "            comm.send(chunk, dest=i, tag=i)\n",
        "\n",
        "        # Master process handles the first chunk\n",
        "        chunk = img_ycbcr[:rows_per_processor, :, :]\n",
        "        compressed_chunk = jpeg_2000_compress_chunk(chunk, threshold)\n",
        "        compressed_data = [compressed_chunk]\n",
        "\n",
        "        for i in range(1, size):\n",
        "            compressed_chunk = comm.recv(source=i, tag=i)\n",
        "            compressed_data.append(compressed_chunk)\n",
        "\n",
        "        return compressed_data, img_ycbcr.shape\n",
        "    else:\n",
        "        # Worker processes receive their chunk and compress it\n",
        "        chunk = comm.recv(source=0, tag=rank)\n",
        "        compressed_chunk = jpeg_2000_compress_chunk(chunk, threshold)\n",
        "        comm.send(compressed_chunk, dest=0, tag=rank)\n",
        "\n",
        "def jpeg_2000_compress_chunk(chunk, threshold):\n",
        "    Y, Cb, Cr = cv2.split(chunk)\n",
        "\n",
        "    # Wavelet transform\n",
        "    coeffs_Y = pywt.wavedec2(Y, 'db1', level=2)\n",
        "    coeffs_Cb = pywt.wavedec2(Cb, 'db1', level=2)\n",
        "    coeffs_Cr = pywt.wavedec2(Cr, 'db1', level=2)\n",
        "\n",
        "    # Quantization\n",
        "    def quantize(coeffs, threshold):\n",
        "        quantized_coeffs = []\n",
        "        for coeff in coeffs:\n",
        "            if isinstance(coeff, tuple):\n",
        "                quantized_coeffs.append(tuple(quantize_coefficients(c, threshold) for c in coeff))\n",
        "            else:\n",
        "                quantized_coeffs.append(quantize_coefficients(coeff, threshold))\n",
        "        return quantized_coeffs\n",
        "\n",
        "    quantized_coeffs_Y = quantize(coeffs_Y, threshold)\n",
        "    quantized_coeffs_Cb = quantize(coeffs_Cb, threshold)\n",
        "    quantized_coeffs_Cr = quantize(coeffs_Cr, threshold)\n",
        "\n",
        "    # Flatten the quantized coefficients for RLE and compression\n",
        "    def flatten_coeffs(coeffs):\n",
        "        flattened = []\n",
        "        for coeff in coeffs:\n",
        "            if isinstance(coeff, tuple):\n",
        "                for c in coeff:\n",
        "                    flattened.extend(c.flatten())\n",
        "            else:\n",
        "                flattened.extend(coeff.flatten())\n",
        "        return np.array(flattened)\n",
        "\n",
        "    flattened_coeffs_Y = flatten_coeffs(quantized_coeffs_Y)\n",
        "    flattened_coeffs_Cb = flatten_coeffs(quantized_coeffs_Cb)\n",
        "    flattened_coeffs_Cr = flatten_coeffs(quantized_coeffs_Cr)\n",
        "\n",
        "    # RLE algorithm and zlib compression\n",
        "    def rle_and_compress(coeffs):\n",
        "        bitstream = ' '.join(f'{k} {len(list(g))}' for k, g in groupby(coeffs))\n",
        "        return zlib.compress(bitstream.encode())\n",
        "\n",
        "    compressed_coeffs_Y = rle_and_compress(flattened_coeffs_Y)\n",
        "    compressed_coeffs_Cb = rle_and_compress(flattened_coeffs_Cb)\n",
        "    compressed_coeffs_Cr = rle_and_compress(flattened_coeffs_Cr)\n",
        "\n",
        "    return compressed_coeffs_Y, compressed_coeffs_Cb, compressed_coeffs_Cr, chunk.shape\n",
        "\n",
        "# Decoding process\n",
        "def parallel_jpeg_2000_decompression(compressed_data, shape, threshold=10):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        rows_per_processor = shape[0] // size\n",
        "        chunks = []\n",
        "        for i in range(size):\n",
        "            start_row = i * rows_per_processor\n",
        "            end_row = (i + 1) * rows_per_processor if i != size - 1 else shape[0]\n",
        "            compressed_chunk = (compressed_data[i][0], compressed_data[i][1], compressed_data[i][2], (end_row - start_row, shape[1], 3))\n",
        "            chunks.append(compressed_chunk)\n",
        "\n",
        "        for i in range(1, size):\n",
        "            comm.send(chunks[i], dest=i, tag=i)\n",
        "\n",
        "        img_reconstructed = jpeg_2000_decompress_chunk(chunks[0], threshold)\n",
        "        reconstructed_chunks = [img_reconstructed]\n",
        "\n",
        "        for i in range(1, size):\n",
        "            img_reconstructed = comm.recv(source=i, tag=i)\n",
        "            reconstructed_chunks.append(img_reconstructed)\n",
        "\n",
        "        img_reconstructed = np.vstack(reconstructed_chunks)\n",
        "        img_rgb = cv2.cvtColor(img_reconstructed, cv2.COLOR_YCrCb2BGR)\n",
        "        return img_rgb\n",
        "    else:\n",
        "        chunk = comm.recv(source=0, tag=rank)\n",
        "        img_reconstructed = jpeg_2000_decompress_chunk(chunk, threshold)\n",
        "        comm.send(img_reconstructed, dest=0, tag=rank)\n",
        "\n",
        "def jpeg_2000_decompress_chunk(compressed_chunk, threshold):\n",
        "    compressed_coeffs_Y, compressed_coeffs_Cb, compressed_coeffs_Cr, chunk_shape = compressed_chunk\n",
        "\n",
        "    def decompress_and_rle(compressed_coeffs):\n",
        "        bitstream = zlib.decompress(compressed_coeffs).decode().split()\n",
        "        result_split = []\n",
        "        for i in range(0, len(bitstream), 2):\n",
        "            result_split.extend([int(float(bitstream[i]))] * int(bitstream[i + 1]))\n",
        "        return np.array(result_split)\n",
        "\n",
        "    flattened_coeffs_Y = decompress_and_rle(compressed_coeffs_Y)\n",
        "    flattened_coeffs_Cb = decompress_and_rle(compressed_coeffs_Cb)\n",
        "    flattened_coeffs_Cr = decompress_and_rle(compressed_coeffs_Cr)\n",
        "\n",
        "    # Unflatten the coefficients\n",
        "    def unflatten_coeffs(flattened_coeffs, original_coeffs):\n",
        "        unflattened = []\n",
        "        index = 0\n",
        "        for coeff in original_coeffs:\n",
        "            if isinstance(coeff, tuple):\n",
        "                unflattened.append(tuple(flattened_coeffs[index:index+c.size].reshape(c.shape) for c in coeff))\n",
        "                index += sum(c.size for c in coeff)\n",
        "            else:\n",
        "                unflattened.append(flattened_coeffs[index:index+coeff.size].reshape(coeff.shape))\n",
        "                index += coeff.size\n",
        "        return unflattened\n",
        "\n",
        "    # Dummy original coefficients for unflattening (assuming level 2 wavelet transform)\n",
        "    dummy_coeffs_Y = pywt.wavedec2(np.zeros((chunk_shape[0], chunk_shape[1])), 'db1', level=2)\n",
        "    dummy_coeffs_Cb = pywt.wavedec2(np.zeros((chunk_shape[0], chunk_shape[1])), 'db1', level=2)\n",
        "    dummy_coeffs_Cr = pywt.wavedec2(np.zeros((chunk_shape[0], chunk_shape[1])), 'db1', level=2)\n",
        "\n",
        "    dequantized_coeffs_Y = unflatten_coeffs(flattened_coeffs_Y, dummy_coeffs_Y)\n",
        "    dequantized_coeffs_Cb = unflatten_coeffs(flattened_coeffs_Cb, dummy_coeffs_Cb)\n",
        "    dequantized_coeffs_Cr = unflatten_coeffs(flattened_coeffs_Cr, dummy_coeffs_Cr)\n",
        "\n",
        "    # Inverse wavelet transform\n",
        "    Y_reconstructed = pywt.waverec2(dequantized_coeffs_Y, 'db1')\n",
        "    Cb_reconstructed = pywt.waverec2(dequantized_coeffs_Cb, 'db1')\n",
        "    Cr_reconstructed = pywt.waverec2(dequantized_coeffs_Cr, 'db1')\n",
        "\n",
        "    # Convert the reconstructed components to 8-bit unsigned integer format\n",
        "    Y_reconstructed = np.clip(Y_reconstructed, 0, 255).astype(np.uint8)\n",
        "    Cb_reconstructed = np.clip(Cb_reconstructed, 0, 255).astype(np.uint8)\n",
        "    Cr_reconstructed = np.clip(Cr_reconstructed, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Merge the components back into a single image\n",
        "    img_reconstructed = cv2.merge([Y_reconstructed, Cb_reconstructed, Cr_reconstructed])\n",
        "\n",
        "    return img_reconstructed\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    kodim01_path = 'kodim01.png'\n",
        "    compressed_data, shape = parallel_jpeg_2000(kodim01_path, threshold=10)\n",
        "    kodim01_decode = parallel_jpeg_2000_decompression(compressed_data, shape, threshold=10)\n",
        "    filename = \"kodim01_decode_wavelet_parallel.png\"\n",
        "    if MPI.COMM_WORLD.Get_rank() == 0:\n",
        "        cv2.imwrite(filename, kodim01_decode)\n",
        "        print(os.path.getsize(kodim01_path))\n",
        "        print(os.path.getsize(filename))\n"
      ],
      "metadata": {
        "id": "hE9rTFqQGTOw",
        "outputId": "1abef204-c722-488c-cc14-643e1d21a4b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parallel_jpeg_2000.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpiexec --allow-run-as-root parallel_jpeg_2000.py"
      ],
      "metadata": {
        "id": "-yXo_S0GHjQg"
      },
      "execution_count": 167,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}